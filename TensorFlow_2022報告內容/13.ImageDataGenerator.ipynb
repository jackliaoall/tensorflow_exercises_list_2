{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"13.ImageDataGenerator.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN1wwRTbD/y0fHkJUA8X4IW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Ref: \n","https://zhuanlan.zhihu.com/p/30197320\n","\n","https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n","\n","https://keras.io/zh/preprocessing/image/"],"metadata":{"id":"gjqCJXKSixe4"}},{"cell_type":"markdown","source":["## Example of using .flow(x, y):"],"metadata":{"id":"FSgjD67UkEsR"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.datasets import cifar10\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","num_classes = 10\n","\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","y_train = to_categorical(y_train, num_classes)\n","y_test = to_categorical(y_test, num_classes)\n","datagen = ImageDataGenerator(\n","    featurewise_center=True,\n","    featurewise_std_normalization=True,\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    horizontal_flip=True,\n","    validation_split=0.2)\n","# compute quantities required for featurewise normalization\n","# (std, mean, and principal components if ZCA whitening is applied)\n","datagen.fit(x_train)\n","# fits the model on batches with real-time data augmentation:\n","model.fit(datagen.flow(x_train, y_train, batch_size=32,\n","         subset='training'),\n","         validation_data=datagen.flow(x_train, y_train,\n","         batch_size=8, subset='validation'),\n","         steps_per_epoch=len(x_train) / 32, epochs=epochs)\n","# here's a more \"manual\" example\n","for e in range(epochs):\n","    print('Epoch', e)\n","    batches = 0\n","    for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=32):\n","        model.fit(x_batch, y_batch)\n","        batches += 1\n","        if batches >= len(x_train) / 32:\n","            # we need to break the loop by hand because\n","            # the generator loops indefinitely\n","            break"],"metadata":{"id":"myjgM3FkkAww","colab":{"base_uri":"https://localhost:8080/","height":289},"executionInfo":{"status":"error","timestamp":1661824839821,"user_tz":-480,"elapsed":12127,"user":{"displayName":"Liao Jack","userId":"16157886839679822522"}},"outputId":"f883993e-1c4a-43bd-a769-a645d55a4061"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 2s 0us/step\n","170508288/170498071 [==============================] - 2s 0us/step\n"]},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-da873083dcae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# fits the model on batches with real-time data augmentation:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m model.fit(datagen.flow(x_train, y_train, batch_size=32,\n\u001b[0m\u001b[1;32m     24\u001b[0m          subset='training'),\n\u001b[1;32m     25\u001b[0m          validation_data=datagen.flow(x_train, y_train,\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]},{"cell_type":"markdown","source":["## Example of using .flow_from_directory(directory):"],"metadata":{"id":"K3NTftjFkKfI"}},{"cell_type":"code","source":["train_datagen = ImageDataGenerator(\n","        rescale=1./255,\n","        shear_range=0.2,\n","        zoom_range=0.2,\n","        horizontal_flip=True)\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","train_generator = train_datagen.flow_from_directory(\n","        'data/train',\n","        target_size=(150, 150),\n","        batch_size=32,\n","        class_mode='binary')\n","validation_generator = test_datagen.flow_from_directory(\n","        'data/validation',\n","        target_size=(150, 150),\n","        batch_size=32,\n","        class_mode='binary')\n","model.fit(\n","        train_generator,\n","        steps_per_epoch=2000,\n","        epochs=50,\n","        validation_data=validation_generator,\n","        validation_steps=800)"],"metadata":{"id":"WGgzadJJkGQ4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Example of transforming images and masks together."],"metadata":{"id":"NBEwiVNvkeMH"}},{"cell_type":"code","source":["# we create two instances with the same arguments\n","data_gen_args = dict(featurewise_center=True,\n","                     featurewise_std_normalization=True,\n","                     rotation_range=90,\n","                     width_shift_range=0.1,\n","                     height_shift_range=0.1,\n","                     zoom_range=0.2)\n","image_datagen = ImageDataGenerator(**data_gen_args)\n","mask_datagen = ImageDataGenerator(**data_gen_args)\n","# Provide the same seed and keyword arguments to the fit and flow methods\n","seed = 1\n","image_datagen.fit(images, augment=True, seed=seed)\n","mask_datagen.fit(masks, augment=True, seed=seed)\n","image_generator = image_datagen.flow_from_directory(\n","    'data/images',\n","    class_mode=None,\n","    seed=seed)\n","mask_generator = mask_datagen.flow_from_directory(\n","    'data/masks',\n","    class_mode=None,\n","    seed=seed)\n","# combine generators into one which yields image and masks\n","train_generator = zip(image_generator, mask_generator)\n","model.fit(\n","    train_generator,\n","    steps_per_epoch=2000,\n","    epochs=50)"],"metadata":{"id":"M0z1DcTNkeZf"},"execution_count":null,"outputs":[]}]}
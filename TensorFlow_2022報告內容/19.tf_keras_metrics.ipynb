{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://keras.io/zh/metrics/#_1\n",
        "\n",
        "https://zhuanlan.zhihu.com/p/95293440\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/metrics"
      ],
      "metadata": {
        "id": "u_mpUAggF72G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) accuracy\n",
        "該accuracy就是大家熟知的最樸素的accuracy。比如我們有6個樣本，其真實標籤y_true為[0, 1, 3, 3, 4, 2]，但被一個模型預測為了[0, 1, 3, 4, 4, 4]，即y_pred=[0, 1, 3, 4, 4, 4]，那麼該模型的accuracy=4/6=66.67%。\n",
        "\n",
        "\n",
        "y_true = [0, 1, 3, 3, 4, 2]\n",
        "\n",
        "y_pred = [0, 1, 3, 4, 4, 4]\n",
        "\n",
        "accuracy = 4 / 6 = 66.67%"
      ],
      "metadata": {
        "id": "X94ZfPpo3M82"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) binary_accuracy\n",
        "binary_accuracy和accuracy最大的不同就是，它適用於2分類的情況。從上圖中可以看到binary_accuracy的計算除了y_true和y_pred外，還有一個threshold參數，該參數默認為0.5。比如有6個樣本，其y_true為[0, 0, 0, 1, 1, 0]，y_pred為[0.2, 0.3, 0.6, 0.7, 0.8, 0.1]，那麼其binary_accuracy=5/6=87.5%。具體計算方法為：1）將y_pred中的每個預測值和threshold對比，大於threshold的設為1，小於等於threshold的設為0，得到y_pred_new=[0, 0, 1, 1, 1, 0]；2）將y_true和y_pred_new代入到2.1中計算得到最終的binary_accuracy=87.5%。\n",
        "\n",
        "y_true = [0, 0, 0, 1, 1, 0]\n",
        "\n",
        "y_pred = [0.2, 0.3, 0.6, 0.7, 0.8, 0.1] => [0, 0, 1, 1, 1, 0]\n",
        "\n",
        "binary_accuracy = 5 / 6 = 87.5%"
      ],
      "metadata": {
        "id": "PA3gyC7Z3sTN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) categorical_accuracy\n",
        "categorical_accuracy和accuracy也很像。不同的是accuracy針對的是y_true和y_pred都為具體標籤的情況，而categorical_accuracy針對的是y_true為onehot標籤，y_pred為向量的情況。比如有4個樣本，其y_true為[[0, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 0]]，y_pred為[[0.1, 0.6, 0.3], [0.2, 0.7, 0.1], [0.3, 0.6, 0.1], [0.9, 0, 0.1]]，則其categorical_accuracy為75%。具體計算方法為：1）將y_true轉為非onehot的形式，即y_true_new=[2, 1, 1, 0]；2）根據y_pred中的每個樣本預測的分數得到y_pred_new=[1, 1, 1, 0]；3）將y_true_new和y_pred_new代入到2.1中計算得到最終的categorical_accuracy=75%。\n",
        "\n",
        "y_true = [[0, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 0]] => y_true_new = [2, 1, 1, 0]\n",
        "\n",
        "y_pred = [[0.1, 0.6, 0.3], [0.2, 0.7, 0.1], [0.3, 0.6, 0.1], [0.9, 0, 0.1]] => y_pred_new = [1, 1, 1, 0]\n",
        "\n",
        "categorical_accuracy = 75%"
      ],
      "metadata": {
        "id": "B2Pzyqpo3scT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) sparse_categorical_accuracy\n",
        "和categorical_accuracy功能一樣，只是其y_true為非onehot的形式。比如有4個樣本，其y_true為[2， 1， 1， 0]，y_pred為[[0.1, 0.6, 0.3], [0.2, 0.7, 0.1], [0.3, 0.6, 0.1], [0.9, 0, 0.1]]，則其categorical_accuracy為75%。具體計算方法為：1）根據y_pred中的每個樣本預測的分數得到y_pred_new=[1, 1, 1, 0]；2）將y_true和y_pred_new代入到2.1中計算得到最終的categorical_accuracy=75%。\n",
        "\n",
        "y_true = [2， 1， 1， 0]\n",
        "\n",
        "y_pred = [[0.1, 0.6, 0.3], [0.2, 0.7, 0.1], [0.3, 0.6, 0.1], [0.9, 0, 0.1]] => y_pred_new=[1, 1, 1, 0]\n",
        "\n",
        "categorical_accuracy = 75%"
      ],
      "metadata": {
        "id": "GTMACw313sgE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) top_k_categorical_accuracy\n",
        "在categorical_accuracy的基礎上加上top_k。 categorical_accuracy要求樣本在真值類別上的預測分數是在所有類別上預測分數的最大值，才算預測對，而top_k_categorical_accuracy只要求樣本在真值類別上的預測分數排在其在所有類別上的預測分數的前k名就行。比如有4個樣本，其y_true為[[0, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 0]]，y_pred為[[0.3, 0.6, 0.1], [0.5, 0.4, 0.1], [0.3, 0.6, 0.1], [0.9, 0, 0.1]]，根據前面知識我們可以計算得到其categorical_accuracy=50%，但是其top_k_categorical_accuracy是多少呢？答案跟k息息相關。如果k大於或等於3，其top_k_categorical_accuracy毫無疑問是100%，因為總共就3個類別。如果k小於3，那就要計算了，比如k=2，那麼top_k_categorical_accuracy=75%。具體計算方法為：1）將y_true轉為非onehot的形式，即y_true_new=[2, 1, 1, 0]；2）計算y_pred的top_k的label，比如k=2時，y_pred_new = [[0, 1], [0, 1], [0, 1], [0, 2]]；3）根據每個樣本的真實標籤是否在預測標籤的top_k內來統計準確率，上述4個樣本為例，2不在[0, 1]內，1在[0, 1]內，1在[0, 1]內，0在[0, 2]內，4個樣本總共預測對了3個，因此k=2時top_k_categorical_accuracy=75%。說明一下，Keras中計算top_k_categorical_accuracy時默認的k值為5。\n",
        "\n",
        "y_true = [[0, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 0]]\n",
        "\n",
        "y_pred = [[0.3, 0.6, 0.1], [0.5, 0.4, 0.1], [0.3, 0.6, 0.1], [0.9, 0, 0.1]]，\n",
        "\n",
        "根據前面知識我們可以計算得到其categorical_accuracy=50%"
      ],
      "metadata": {
        "id": "xoKexHK03sj7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6) sparse_top_k_categorical_accuracy 和top_k_categorical_accuracy功能一樣，只是其y_true為非onehot的形式。比如有4個樣本，其y_true為[2， 1， 1， 0]，y_pred為[[0.3, 0.6, 0.1], [0.5, 0.4, 0.1], [0.3, 0.6, 0.1], [0.9, 0, 0.1]]。計算sparse_top_k_categorical_accuracy的步驟如下：1）計算y_pred的top_k的label，比如k=2時，y_pred_new = [[0, 1], [0, 1], [0, 1], [0, 2]]；2）根據每個樣本的真實標籤是否在預測標籤的top_k內來統計準確率，上述4個樣本為例，2不在[0, 1]內，1在[0, 1]內，1在[0, 1]內，0在[0, 2]內，4個樣本總共預測對了3個，因此k=2時top_k_categorical_accuracy=75%。"
      ],
      "metadata": {
        "id": "-qM9lUrZ3snU"
      }
    }
  ]
}